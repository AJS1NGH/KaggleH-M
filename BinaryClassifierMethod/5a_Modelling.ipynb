{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f0987ab-5816-4f93-8e31-3aa1828dd731",
   "metadata": {},
   "source": [
    "Trains a 2 head neural network classifier to predict whether a user will purchase a paired product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59ac6a17-e389-430b-8cbb-c06e82aa9865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, os, numpy as np\n",
    "import plotly.express as px\n",
    "pd.options.display.max_columns = 50\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import regularizers\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db2d8c69-54b9-4309-93e9-3e5a803dadc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../data/sampleTrain.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcf53cb9-4fdf-4174-ae30-94ae7f02e260",
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cfd30a5-6cf2-47e6-bdf8-4b2c9f80b63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = []\n",
    "val_indices = []\n",
    "for train_index, val_index in sss.split(df, df['Y']):\n",
    "    train_indices.append(train_index)\n",
    "    val_indices.append(val_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8546e285-23e7-4fd8-93a5-8d3a35fa9231",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.iloc[train_indices[0]].reset_index(drop=True).copy()\n",
    "val_df = df.iloc[val_indices[0]].reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d93a35a8-963d-47ca-b6a6-cb3c4525df57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_0</th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>c_4</th>\n",
       "      <th>c_5</th>\n",
       "      <th>c_6</th>\n",
       "      <th>c_7</th>\n",
       "      <th>c_8</th>\n",
       "      <th>c_9</th>\n",
       "      <th>c_10</th>\n",
       "      <th>c_11</th>\n",
       "      <th>c_12</th>\n",
       "      <th>c_13</th>\n",
       "      <th>c_14</th>\n",
       "      <th>c_15</th>\n",
       "      <th>c_16</th>\n",
       "      <th>c_17</th>\n",
       "      <th>c_18</th>\n",
       "      <th>c_19</th>\n",
       "      <th>c_20</th>\n",
       "      <th>c_21</th>\n",
       "      <th>c_22</th>\n",
       "      <th>c_23</th>\n",
       "      <th>c_24</th>\n",
       "      <th>...</th>\n",
       "      <th>a_489</th>\n",
       "      <th>a_490</th>\n",
       "      <th>a_491</th>\n",
       "      <th>a_492</th>\n",
       "      <th>a_493</th>\n",
       "      <th>a_494</th>\n",
       "      <th>a_495</th>\n",
       "      <th>a_496</th>\n",
       "      <th>a_497</th>\n",
       "      <th>a_498</th>\n",
       "      <th>a_499</th>\n",
       "      <th>a_500</th>\n",
       "      <th>a_501</th>\n",
       "      <th>a_502</th>\n",
       "      <th>a_503</th>\n",
       "      <th>a_504</th>\n",
       "      <th>a_505</th>\n",
       "      <th>a_506</th>\n",
       "      <th>a_507</th>\n",
       "      <th>a_508</th>\n",
       "      <th>a_509</th>\n",
       "      <th>a_510</th>\n",
       "      <th>a_511</th>\n",
       "      <th>Y</th>\n",
       "      <th>Q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.007609</td>\n",
       "      <td>0.032056</td>\n",
       "      <td>-0.037316</td>\n",
       "      <td>-0.021332</td>\n",
       "      <td>0.047567</td>\n",
       "      <td>0.023968</td>\n",
       "      <td>0.053063</td>\n",
       "      <td>0.068663</td>\n",
       "      <td>0.020005</td>\n",
       "      <td>-0.021283</td>\n",
       "      <td>-0.055241</td>\n",
       "      <td>0.047815</td>\n",
       "      <td>0.034351</td>\n",
       "      <td>0.004660</td>\n",
       "      <td>0.054117</td>\n",
       "      <td>0.014661</td>\n",
       "      <td>0.060061</td>\n",
       "      <td>0.034148</td>\n",
       "      <td>0.027116</td>\n",
       "      <td>0.044250</td>\n",
       "      <td>-0.061070</td>\n",
       "      <td>0.037993</td>\n",
       "      <td>0.026378</td>\n",
       "      <td>-0.021512</td>\n",
       "      <td>0.035432</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045832</td>\n",
       "      <td>-0.010256</td>\n",
       "      <td>-0.021925</td>\n",
       "      <td>0.019728</td>\n",
       "      <td>-0.048264</td>\n",
       "      <td>-0.042763</td>\n",
       "      <td>0.022530</td>\n",
       "      <td>-0.050692</td>\n",
       "      <td>0.026909</td>\n",
       "      <td>0.032411</td>\n",
       "      <td>-0.054654</td>\n",
       "      <td>-0.048282</td>\n",
       "      <td>0.073165</td>\n",
       "      <td>0.014169</td>\n",
       "      <td>-0.046194</td>\n",
       "      <td>0.020750</td>\n",
       "      <td>0.049168</td>\n",
       "      <td>0.036420</td>\n",
       "      <td>-0.066694</td>\n",
       "      <td>0.012602</td>\n",
       "      <td>0.008862</td>\n",
       "      <td>-0.030414</td>\n",
       "      <td>0.027437</td>\n",
       "      <td>0</td>\n",
       "      <td>723819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.033950</td>\n",
       "      <td>0.057984</td>\n",
       "      <td>-0.071288</td>\n",
       "      <td>-0.043218</td>\n",
       "      <td>0.001485</td>\n",
       "      <td>0.071466</td>\n",
       "      <td>0.057743</td>\n",
       "      <td>0.082931</td>\n",
       "      <td>0.079448</td>\n",
       "      <td>-0.050903</td>\n",
       "      <td>-0.068545</td>\n",
       "      <td>0.055255</td>\n",
       "      <td>0.063914</td>\n",
       "      <td>-0.009430</td>\n",
       "      <td>0.052944</td>\n",
       "      <td>0.025674</td>\n",
       "      <td>0.038944</td>\n",
       "      <td>0.045122</td>\n",
       "      <td>0.012483</td>\n",
       "      <td>0.063228</td>\n",
       "      <td>-0.038934</td>\n",
       "      <td>0.054356</td>\n",
       "      <td>0.007674</td>\n",
       "      <td>-0.039047</td>\n",
       "      <td>0.012491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057799</td>\n",
       "      <td>0.017770</td>\n",
       "      <td>0.031712</td>\n",
       "      <td>0.033335</td>\n",
       "      <td>-0.053662</td>\n",
       "      <td>-0.017807</td>\n",
       "      <td>-0.039433</td>\n",
       "      <td>-0.040054</td>\n",
       "      <td>0.008012</td>\n",
       "      <td>0.009530</td>\n",
       "      <td>0.009211</td>\n",
       "      <td>-0.024321</td>\n",
       "      <td>0.071141</td>\n",
       "      <td>-0.035914</td>\n",
       "      <td>-0.022758</td>\n",
       "      <td>0.046278</td>\n",
       "      <td>0.047825</td>\n",
       "      <td>-0.070064</td>\n",
       "      <td>-0.068126</td>\n",
       "      <td>-0.001557</td>\n",
       "      <td>-0.016637</td>\n",
       "      <td>-0.051852</td>\n",
       "      <td>0.038415</td>\n",
       "      <td>0</td>\n",
       "      <td>934283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.042539</td>\n",
       "      <td>0.042159</td>\n",
       "      <td>0.020725</td>\n",
       "      <td>0.008295</td>\n",
       "      <td>-0.002174</td>\n",
       "      <td>-0.007319</td>\n",
       "      <td>0.039410</td>\n",
       "      <td>0.063293</td>\n",
       "      <td>0.029742</td>\n",
       "      <td>-0.001772</td>\n",
       "      <td>-0.046326</td>\n",
       "      <td>0.041718</td>\n",
       "      <td>0.005290</td>\n",
       "      <td>-0.000150</td>\n",
       "      <td>0.023447</td>\n",
       "      <td>0.025195</td>\n",
       "      <td>0.029470</td>\n",
       "      <td>0.043531</td>\n",
       "      <td>0.014864</td>\n",
       "      <td>0.040745</td>\n",
       "      <td>-0.061941</td>\n",
       "      <td>-0.010867</td>\n",
       "      <td>0.049788</td>\n",
       "      <td>-0.038780</td>\n",
       "      <td>0.027389</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019025</td>\n",
       "      <td>-0.003937</td>\n",
       "      <td>0.004133</td>\n",
       "      <td>-0.021396</td>\n",
       "      <td>-0.062676</td>\n",
       "      <td>0.006624</td>\n",
       "      <td>0.041481</td>\n",
       "      <td>0.021502</td>\n",
       "      <td>0.032379</td>\n",
       "      <td>-0.019148</td>\n",
       "      <td>-0.015441</td>\n",
       "      <td>-0.065368</td>\n",
       "      <td>0.076031</td>\n",
       "      <td>-0.053625</td>\n",
       "      <td>-0.063819</td>\n",
       "      <td>-0.027560</td>\n",
       "      <td>0.045164</td>\n",
       "      <td>-0.001526</td>\n",
       "      <td>-0.003567</td>\n",
       "      <td>-0.001584</td>\n",
       "      <td>-0.029391</td>\n",
       "      <td>-0.043211</td>\n",
       "      <td>0.024269</td>\n",
       "      <td>1</td>\n",
       "      <td>898888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.024661</td>\n",
       "      <td>0.033532</td>\n",
       "      <td>-0.037073</td>\n",
       "      <td>-0.029151</td>\n",
       "      <td>-0.004612</td>\n",
       "      <td>0.052987</td>\n",
       "      <td>0.077461</td>\n",
       "      <td>0.077839</td>\n",
       "      <td>0.082593</td>\n",
       "      <td>-0.058052</td>\n",
       "      <td>-0.034719</td>\n",
       "      <td>0.066648</td>\n",
       "      <td>0.061546</td>\n",
       "      <td>-0.001921</td>\n",
       "      <td>0.070346</td>\n",
       "      <td>0.062135</td>\n",
       "      <td>0.024700</td>\n",
       "      <td>0.030859</td>\n",
       "      <td>0.044692</td>\n",
       "      <td>0.054330</td>\n",
       "      <td>-0.053047</td>\n",
       "      <td>0.054074</td>\n",
       "      <td>0.019816</td>\n",
       "      <td>-0.030229</td>\n",
       "      <td>0.019991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006226</td>\n",
       "      <td>-0.027783</td>\n",
       "      <td>0.030283</td>\n",
       "      <td>0.020046</td>\n",
       "      <td>-0.052551</td>\n",
       "      <td>-0.037479</td>\n",
       "      <td>0.059561</td>\n",
       "      <td>-0.034385</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>-0.033954</td>\n",
       "      <td>-0.038600</td>\n",
       "      <td>-0.036415</td>\n",
       "      <td>0.075786</td>\n",
       "      <td>0.019143</td>\n",
       "      <td>-0.059735</td>\n",
       "      <td>0.007111</td>\n",
       "      <td>0.069468</td>\n",
       "      <td>-0.072330</td>\n",
       "      <td>-0.064835</td>\n",
       "      <td>0.045485</td>\n",
       "      <td>-0.040182</td>\n",
       "      <td>-0.046414</td>\n",
       "      <td>0.029894</td>\n",
       "      <td>0</td>\n",
       "      <td>1340140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.020129</td>\n",
       "      <td>0.057922</td>\n",
       "      <td>-0.072309</td>\n",
       "      <td>-0.050506</td>\n",
       "      <td>0.046882</td>\n",
       "      <td>0.034397</td>\n",
       "      <td>0.069011</td>\n",
       "      <td>0.074125</td>\n",
       "      <td>0.066629</td>\n",
       "      <td>-0.059258</td>\n",
       "      <td>-0.038325</td>\n",
       "      <td>0.037379</td>\n",
       "      <td>0.070386</td>\n",
       "      <td>-0.042335</td>\n",
       "      <td>0.056509</td>\n",
       "      <td>0.045679</td>\n",
       "      <td>0.045406</td>\n",
       "      <td>0.017677</td>\n",
       "      <td>0.054679</td>\n",
       "      <td>0.063565</td>\n",
       "      <td>-0.029087</td>\n",
       "      <td>0.041543</td>\n",
       "      <td>0.038013</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>-0.001023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037448</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>0.036073</td>\n",
       "      <td>-0.025943</td>\n",
       "      <td>-0.057222</td>\n",
       "      <td>0.008719</td>\n",
       "      <td>0.003525</td>\n",
       "      <td>0.020458</td>\n",
       "      <td>0.020510</td>\n",
       "      <td>-0.017395</td>\n",
       "      <td>0.032116</td>\n",
       "      <td>0.018903</td>\n",
       "      <td>0.077522</td>\n",
       "      <td>-0.037799</td>\n",
       "      <td>-0.054228</td>\n",
       "      <td>-0.001145</td>\n",
       "      <td>0.065842</td>\n",
       "      <td>-0.072806</td>\n",
       "      <td>-0.036529</td>\n",
       "      <td>0.048998</td>\n",
       "      <td>-0.042488</td>\n",
       "      <td>-0.068159</td>\n",
       "      <td>0.050766</td>\n",
       "      <td>0</td>\n",
       "      <td>1059697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1026 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        c_0       c_1       c_2       c_3       c_4       c_5       c_6  \\\n",
       "0 -0.007609  0.032056 -0.037316 -0.021332  0.047567  0.023968  0.053063   \n",
       "1 -0.033950  0.057984 -0.071288 -0.043218  0.001485  0.071466  0.057743   \n",
       "2 -0.042539  0.042159  0.020725  0.008295 -0.002174 -0.007319  0.039410   \n",
       "3 -0.024661  0.033532 -0.037073 -0.029151 -0.004612  0.052987  0.077461   \n",
       "4 -0.020129  0.057922 -0.072309 -0.050506  0.046882  0.034397  0.069011   \n",
       "\n",
       "        c_7       c_8       c_9      c_10      c_11      c_12      c_13  \\\n",
       "0  0.068663  0.020005 -0.021283 -0.055241  0.047815  0.034351  0.004660   \n",
       "1  0.082931  0.079448 -0.050903 -0.068545  0.055255  0.063914 -0.009430   \n",
       "2  0.063293  0.029742 -0.001772 -0.046326  0.041718  0.005290 -0.000150   \n",
       "3  0.077839  0.082593 -0.058052 -0.034719  0.066648  0.061546 -0.001921   \n",
       "4  0.074125  0.066629 -0.059258 -0.038325  0.037379  0.070386 -0.042335   \n",
       "\n",
       "       c_14      c_15      c_16      c_17      c_18      c_19      c_20  \\\n",
       "0  0.054117  0.014661  0.060061  0.034148  0.027116  0.044250 -0.061070   \n",
       "1  0.052944  0.025674  0.038944  0.045122  0.012483  0.063228 -0.038934   \n",
       "2  0.023447  0.025195  0.029470  0.043531  0.014864  0.040745 -0.061941   \n",
       "3  0.070346  0.062135  0.024700  0.030859  0.044692  0.054330 -0.053047   \n",
       "4  0.056509  0.045679  0.045406  0.017677  0.054679  0.063565 -0.029087   \n",
       "\n",
       "       c_21      c_22      c_23      c_24  ...     a_489     a_490     a_491  \\\n",
       "0  0.037993  0.026378 -0.021512  0.035432  ... -0.045832 -0.010256 -0.021925   \n",
       "1  0.054356  0.007674 -0.039047  0.012491  ...  0.057799  0.017770  0.031712   \n",
       "2 -0.010867  0.049788 -0.038780  0.027389  ... -0.019025 -0.003937  0.004133   \n",
       "3  0.054074  0.019816 -0.030229  0.019991  ...  0.006226 -0.027783  0.030283   \n",
       "4  0.041543  0.038013  0.002830 -0.001023  ...  0.037448  0.003398  0.036073   \n",
       "\n",
       "      a_492     a_493     a_494     a_495     a_496     a_497     a_498  \\\n",
       "0  0.019728 -0.048264 -0.042763  0.022530 -0.050692  0.026909  0.032411   \n",
       "1  0.033335 -0.053662 -0.017807 -0.039433 -0.040054  0.008012  0.009530   \n",
       "2 -0.021396 -0.062676  0.006624  0.041481  0.021502  0.032379 -0.019148   \n",
       "3  0.020046 -0.052551 -0.037479  0.059561 -0.034385  0.000791 -0.033954   \n",
       "4 -0.025943 -0.057222  0.008719  0.003525  0.020458  0.020510 -0.017395   \n",
       "\n",
       "      a_499     a_500     a_501     a_502     a_503     a_504     a_505  \\\n",
       "0 -0.054654 -0.048282  0.073165  0.014169 -0.046194  0.020750  0.049168   \n",
       "1  0.009211 -0.024321  0.071141 -0.035914 -0.022758  0.046278  0.047825   \n",
       "2 -0.015441 -0.065368  0.076031 -0.053625 -0.063819 -0.027560  0.045164   \n",
       "3 -0.038600 -0.036415  0.075786  0.019143 -0.059735  0.007111  0.069468   \n",
       "4  0.032116  0.018903  0.077522 -0.037799 -0.054228 -0.001145  0.065842   \n",
       "\n",
       "      a_506     a_507     a_508     a_509     a_510     a_511  Y        Q  \n",
       "0  0.036420 -0.066694  0.012602  0.008862 -0.030414  0.027437  0   723819  \n",
       "1 -0.070064 -0.068126 -0.001557 -0.016637 -0.051852  0.038415  0   934283  \n",
       "2 -0.001526 -0.003567 -0.001584 -0.029391 -0.043211  0.024269  1   898888  \n",
       "3 -0.072330 -0.064835  0.045485 -0.040182 -0.046414  0.029894  0  1340140  \n",
       "4 -0.072806 -0.036529  0.048998 -0.042488 -0.068159  0.050766  0  1059697  \n",
       "\n",
       "[5 rows x 1026 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8426b3c6-4317-4fb9-b8cf-9325bba282ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.drop(['Y','Q'], axis=1).copy()\n",
    "x_val = val_df.drop(['Y','Q'], axis=1).copy()\n",
    "\n",
    "y_train = train_df['Y'].values\n",
    "y_val = val_df['Y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0344f491-4857-41a2-9c55-032c52de815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_xtrain = x_train[['c_' + str(x) for x in range(512)]].copy()\n",
    "cf_xval = x_val[['c_' + str(x) for x in range(512)]].copy()\n",
    "\n",
    "af_xtrain = x_train[['a_' + str(x) for x in range(512)]].copy()\n",
    "af_xval = x_val[['a_' + str(x) for x in range(512)]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "782c32dd-b702-41bc-9431-71cde4095757",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6c490e7-357a-4d6d-9427-207103d394e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=((TensorSpec(shape=(None, 512), dtype=tf.float32, name=None), TensorSpec(shape=(None, 512), dtype=tf.float32, name=None)), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_train_loss = []\n",
    "fold_val_loss = []\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(((cf_xtrain, af_xtrain), y_train))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(((cf_xval, af_xval), y_val))\n",
    "\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fc8eb11-31ba-4905-a669-0745db778e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    cf_inputs = tf.keras.Input((512, ))\n",
    "    af_inputs = tf.keras.Input((512, ))\n",
    "    \n",
    "    cf_x = layers.Dense(25, activation='relu')(cf_inputs)\n",
    "    cf_x = layers.Dense(12, activation='relu')(cf_x)\n",
    "    \n",
    "    af_x = layers.Dense(25, activation='relu')(af_inputs)\n",
    "    af_x = layers.Dense(12, activation='relu')(af_x)\n",
    "    \n",
    "    fx = layers.Concatenate(axis=1)([cf_x, af_x])\n",
    "    fx = layers.Dense(20, activation='relu', kernel_regularizer=regularizers.l2(0.001))(fx)\n",
    "    fx = layers.Dense(10, activation='relu', kernel_regularizer=regularizers.l2(0.001))(fx)\n",
    "    out = layers.Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(0.001))(fx)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[cf_inputs, af_inputs], outputs=out)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.SGD(0.01),\n",
    "                 metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75fc7a6a-5f85-4916-8a14-fa059d60849e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 25)           12825       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 25)           12825       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 12)           312         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 12)           312         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 24)           0           ['dense_1[0][0]',                \n",
      "                                                                  'dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 20)           500         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 10)           210         ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 1)            11          ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 26,995\n",
      "Trainable params: 26,995\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "dnn = get_model()\n",
    "dnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71c09017-5301-4857-aa82-c9b243a7dfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(y_train)\n",
    "pos = sum(y_train)\n",
    "neg = total-pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8eeeaaeb-7636-4880-acae-28b4df8e60c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for class 0: 0.63\n",
      "Weight for class 1: 2.45\n"
     ]
    }
   ],
   "source": [
    "weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70c9e2a4-a4d5-4bfd-8d03-7abffe964854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7955937366883079"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - sum(y_train)/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf8e0c33-1b6f-42e4-8bee-d904890d9b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7955924180042564"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - sum(y_val)/len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed5a555d-4abe-4f74-897a-80044468cdd3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "9427/9427 [==============================] - 69s 7ms/step - loss: 0.7084 - accuracy: 0.5614 - val_loss: 0.6268 - val_accuracy: 0.6830\n",
      "Epoch 2/30\n",
      "9427/9427 [==============================] - 68s 7ms/step - loss: 0.6054 - accuracy: 0.6808 - val_loss: 0.5855 - val_accuracy: 0.6964\n",
      "Epoch 3/30\n",
      "9427/9427 [==============================] - 68s 7ms/step - loss: 0.5825 - accuracy: 0.7000 - val_loss: 0.5750 - val_accuracy: 0.7037\n",
      "Epoch 4/30\n",
      "9427/9427 [==============================] - 69s 7ms/step - loss: 0.5686 - accuracy: 0.7124 - val_loss: 0.5650 - val_accuracy: 0.7135\n",
      "Epoch 5/30\n",
      "9427/9427 [==============================] - 69s 7ms/step - loss: 0.5572 - accuracy: 0.7242 - val_loss: 0.5601 - val_accuracy: 0.7195\n",
      "Epoch 6/30\n",
      "9427/9427 [==============================] - 69s 7ms/step - loss: 0.5476 - accuracy: 0.7344 - val_loss: 0.5617 - val_accuracy: 0.7214\n",
      "Epoch 7/30\n",
      "9427/9427 [==============================] - 69s 7ms/step - loss: 0.5398 - accuracy: 0.7426 - val_loss: 0.5605 - val_accuracy: 0.7260\n",
      "Epoch 8/30\n",
      "9427/9427 [==============================] - 68s 7ms/step - loss: 0.5333 - accuracy: 0.7495 - val_loss: 0.5502 - val_accuracy: 0.7362\n",
      "Epoch 9/30\n",
      "9427/9427 [==============================] - 69s 7ms/step - loss: 0.5278 - accuracy: 0.7553 - val_loss: 0.5401 - val_accuracy: 0.7438\n",
      "Epoch 10/30\n",
      "9427/9427 [==============================] - 69s 7ms/step - loss: 0.5231 - accuracy: 0.7598 - val_loss: 0.5379 - val_accuracy: 0.7465\n",
      "Epoch 11/30\n",
      "9427/9427 [==============================] - 69s 7ms/step - loss: 0.5190 - accuracy: 0.7646 - val_loss: 0.5315 - val_accuracy: 0.7541\n",
      "Epoch 12/30\n",
      "9427/9427 [==============================] - 69s 7ms/step - loss: 0.5155 - accuracy: 0.7685 - val_loss: 0.5253 - val_accuracy: 0.7602\n",
      "Epoch 13/30\n",
      "9427/9427 [==============================] - 69s 7ms/step - loss: 0.5123 - accuracy: 0.7721 - val_loss: 0.5206 - val_accuracy: 0.7637\n",
      "Epoch 14/30\n",
      "9427/9427 [==============================] - 69s 7ms/step - loss: 0.5095 - accuracy: 0.7750 - val_loss: 0.5197 - val_accuracy: 0.7647\n",
      "Epoch 15/30\n",
      "9427/9427 [==============================] - 69s 7ms/step - loss: 0.5069 - accuracy: 0.7777 - val_loss: 0.5180 - val_accuracy: 0.7664\n",
      "Epoch 16/30\n",
      "9427/9427 [==============================] - 69s 7ms/step - loss: 0.5046 - accuracy: 0.7801 - val_loss: 0.5128 - val_accuracy: 0.7701\n",
      "Epoch 17/30\n",
      "9427/9427 [==============================] - 68s 7ms/step - loss: 0.5025 - accuracy: 0.7821 - val_loss: 0.5121 - val_accuracy: 0.7710\n",
      "Epoch 18/30\n",
      "9427/9427 [==============================] - 69s 7ms/step - loss: 0.5005 - accuracy: 0.7839 - val_loss: 0.5099 - val_accuracy: 0.7729\n",
      "Epoch 19/30\n",
      "9427/9427 [==============================] - 68s 7ms/step - loss: 0.4987 - accuracy: 0.7856 - val_loss: 0.5071 - val_accuracy: 0.7759\n",
      "Epoch 20/30\n",
      "9427/9427 [==============================] - 68s 7ms/step - loss: 0.4969 - accuracy: 0.7869 - val_loss: 0.5174 - val_accuracy: 0.7669\n",
      "Epoch 21/30\n",
      "9427/9427 [==============================] - 68s 7ms/step - loss: 0.4953 - accuracy: 0.7883 - val_loss: 0.5195 - val_accuracy: 0.7654\n",
      "Epoch 22/30\n",
      "9427/9427 [==============================] - 68s 7ms/step - loss: 0.4938 - accuracy: 0.7898 - val_loss: 0.5126 - val_accuracy: 0.7707\n",
      "Epoch 23/30\n",
      "9427/9427 [==============================] - 68s 7ms/step - loss: 0.4924 - accuracy: 0.7912 - val_loss: 0.5179 - val_accuracy: 0.7678\n",
      "Epoch 24/30\n",
      "9427/9427 [==============================] - 69s 7ms/step - loss: 0.4909 - accuracy: 0.7924 - val_loss: 0.5191 - val_accuracy: 0.7676\n",
      "Epoch 25/30\n",
      "9427/9427 [==============================] - 69s 7ms/step - loss: 0.4896 - accuracy: 0.7935 - val_loss: 0.5199 - val_accuracy: 0.7672\n",
      "Epoch 26/30\n",
      "9427/9427 [==============================] - 69s 7ms/step - loss: 0.4883 - accuracy: 0.7948 - val_loss: 0.5243 - val_accuracy: 0.7643\n",
      "Epoch 27/30\n",
      "9427/9427 [==============================] - 72s 8ms/step - loss: 0.4871 - accuracy: 0.7958 - val_loss: 0.5238 - val_accuracy: 0.7647\n",
      "Epoch 28/30\n",
      "1340/9427 [===>..........................] - ETA: 53s - loss: 0.4885 - accuracy: 0.7946"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5176/2760369858.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = dnn.fit(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     verbose=1, epochs=30, workers=1, shuffle=False, class_weight=class_weight)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = dnn.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    verbose=1, epochs=30, workers=1, shuffle=False, class_weight=class_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b842152-04f8-40f5-831c-328eb1444a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/dnn1\\assets\n"
     ]
    }
   ],
   "source": [
    "dnn.save('../models/dnn1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bbf0bd3c-a0ce-4d33-88fd-70a5989c5702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2357/2357 [==============================] - 4s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = dnn.predict(val_dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b4edbbe-1550-40a8-b798-54318ddb9fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce8bd00f-fcd1-4bcd-8eb3-1fa27dd19027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13393596"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17fcec90-d05e-417d-a1e1-ddf10fb6643a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07b37cec-6c4c-4e7f-82db-cff5b09fd9d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13393596, 0.26480663, 0.21671613, 0.14147896, 0.28341255,\n",
       "       0.17072555, 0.14309306, 0.15220736, 0.5992796 , 0.22587974,\n",
       "       0.30867004, 0.17417048, 0.06664606, 0.16928484, 0.93908167,\n",
       "       0.7696869 , 0.8526217 , 0.3855799 , 0.0713409 , 0.92872137,\n",
       "       0.95502585, 0.5422059 , 0.12449035, 0.12228905, 0.9467503 ,\n",
       "       0.31891862, 0.13804312, 0.8031897 , 0.84503895, 0.40104243,\n",
       "       0.5333662 , 0.20282413, 0.16526753, 0.8146628 , 0.18562071,\n",
       "       0.71643573, 0.7633169 , 0.396171  , 0.63372844, 0.16468744],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c20095-7588-4ac0-a481-a9ce2895648e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
